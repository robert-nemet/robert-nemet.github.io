<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Kubernetes: Exposing Services and Horizontal Pod Autoscaler | DevCube</title>
<meta name=keywords content="k8s,kubernetes,basics,services,hpa,scaling"><meta name=description content="This post is the third part of the series about Kubernetes for beginners. In the
second part, I introduced the K8s and its basic
components. In the second part, I discussed containers, pods, and deployments.
This post will discuss services(SVC) and horizontal pod autoscaler(HPA).

In this short post, I will discuss how to expose your services to the outside world
and scale your applications based on the load.
Exposing Deployments: Services
When you create a Deployment, you&rsquo;ll get Pods running your app. So, start local K8s
cluster and deploy an app:"><meta name=author content="Robert Nemet"><link rel=canonical href=https://rnemet.dev/posts/practical_k8s/k8s_intro_svc_hpa/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://rnemet.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rnemet.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rnemet.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://rnemet.dev/apple-touch-icon.png><link rel=mask-icon href=https://rnemet.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://rnemet.dev/posts/practical_k8s/k8s_intro_svc_hpa/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-L148RQBR36"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-L148RQBR36")}</script><meta property="og:url" content="https://rnemet.dev/posts/practical_k8s/k8s_intro_svc_hpa/"><meta property="og:site_name" content="DevCube"><meta property="og:title" content="Kubernetes: Exposing Services and Horizontal Pod Autoscaler"><meta property="og:description" content="This post is the third part of the series about Kubernetes for beginners. In the second part, I introduced the K8s and its basic components. In the second part, I discussed containers, pods, and deployments. This post will discuss services(SVC) and horizontal pod autoscaler(HPA).
In this short post, I will discuss how to expose your services to the outside world and scale your applications based on the load.
Exposing Deployments: Services When you create a Deployment, you’ll get Pods running your app. So, start local K8s cluster and deploy an app:"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-06T20:46:44+02:00"><meta property="article:modified_time" content="2025-02-06T20:46:44+02:00"><meta property="article:tag" content="K8s"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Basics"><meta property="article:tag" content="Services"><meta property="article:tag" content="Hpa"><meta property="article:tag" content="Scaling"><meta property="og:image" content="https://rnemet.dev/images/k8s_intro_svc_hpa.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://rnemet.dev/images/k8s_intro_svc_hpa.png"><meta name=twitter:title content="Kubernetes: Exposing Services and Horizontal Pod Autoscaler"><meta name=twitter:description content="This post is the third part of the series about Kubernetes for beginners. In the
second part, I introduced the K8s and its basic
components. In the second part, I discussed containers, pods, and deployments.
This post will discuss services(SVC) and horizontal pod autoscaler(HPA).

In this short post, I will discuss how to expose your services to the outside world
and scale your applications based on the load.
Exposing Deployments: Services
When you create a Deployment, you&rsquo;ll get Pods running your app. So, start local K8s
cluster and deploy an app:"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://rnemet.dev/posts/"},{"@type":"ListItem","position":2,"name":"Practical Kubernetes","item":"https://rnemet.dev/posts/practical_k8s/"},{"@type":"ListItem","position":3,"name":"Kubernetes: Exposing Services and Horizontal Pod Autoscaler","item":"https://rnemet.dev/posts/practical_k8s/k8s_intro_svc_hpa/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Kubernetes: Exposing Services and Horizontal Pod Autoscaler","name":"Kubernetes: Exposing Services and Horizontal Pod Autoscaler","description":"This post is the third part of the series about Kubernetes for beginners. In the second part, I introduced the K8s and its basic components. In the second part, I discussed containers, pods, and deployments. This post will discuss services(SVC) and horizontal pod autoscaler(HPA).\nIn this short post, I will discuss how to expose your services to the outside world and scale your applications based on the load.\nExposing Deployments: Services When you create a Deployment, you\u0026rsquo;ll get Pods running your app. So, start local K8s cluster and deploy an app:\n","keywords":["k8s","kubernetes","basics","services","hpa","scaling"],"articleBody":"This post is the third part of the series about Kubernetes for beginners. In the second part, I introduced the K8s and its basic components. In the second part, I discussed containers, pods, and deployments. This post will discuss services(SVC) and horizontal pod autoscaler(HPA).\nIn this short post, I will discuss how to expose your services to the outside world and scale your applications based on the load.\nExposing Deployments: Services When you create a Deployment, you’ll get Pods running your app. So, start local K8s cluster and deploy an app:\nkubectl create deployment nginx --image=nginx The above command will create a Deployment named nginx with a single Pod running the nginx image. You can check the status of Deployment and Pods:\n$ kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE nginx 1/1 1 1 4m8s The above line tells you that Deployment nginx has one Pod running and is up-to-date. Now, let’s check Pods:\n$ kubectl get pods NAME READY STATUS RESTARTS AGE nginx-676b6c5bbc-qzxsh 1/1 Running 0 6m22s Now, add one more Pod:\n$ kubectl run busybox --image busybox --restart=Never --rm -it -- sh I’m adding a Pod named busybox with the busybox image. I want to use this Pod to test the connection to the nginx Pod. The above command creates a Pod, runs a shell, and removes the Pod when you exit the shell. Before I test the connection, open a new terminal and run the following:\n$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES busybox 1/1 Running 0 2m16s 10.42.0.63 lima-k3s nginx-676b6c5bbc-qzxsh 1/1 Running 0 43m 10.42.0.60 lima-k3s Using the output wide option, you can see the IP addresses of the Pods. Now you see each Pod has its IP address. Go back to the first terminal(busybox) and run:\n$ wget -qO- http://10.42.0.60 You should get a response from the nginx Pod. It should be the default Nginx page. Now let’s kill the nginx Pod:\n$ kubectl delete pod nginx-676b6c5bbc-qzxsh pod \"nginx-676b6c5bbc-qzxsh\" deleted If you run the wget command again, you’ll get an error. The Pod is gone. Recheck Pods:\n$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES busybox 1/1 Running 0 8m49s 10.42.0.63 lima-k3s nginx-676b6c5bbc-zbwl5 1/1 Running 0 2m4s 10.42.0.64 lima-k3s Notice several things:\nThe old Pod is gone(nginx-676b6c5bbc-qzxsh). A new Pod(nginx-676b6c5bbc-zbwl5) replaces the old one. The new Pod has a different IP address. Deployment ensures that the desired number of Pods is running. If a Pod dies, it creates a new one. So, if I want to call nginx again, I need to know its new IP. I need something to abstract the Pod IP addresses. For this purpose, I’ll use K8s Services. K8s Service is a K8s component(resource) for exposing one or more Pods. You can think of it as a load balancer for your Pods. Let’s create a Service for the nginx Deployment:\n$ kubectl expose deployment nginx --port 80 service/nginx exposed Explore services:\nkubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.43.0.1 443/TCP 5d2h nginx ClusterIP 10.43.38.173 80/TCP 30s The above output shows two services: kubernetes and nginx. The kubernetes Service is a default service for the K8s cluster. The nginx service is the one I created. It has a ClusterIP address and listens on port 80. The nginx service is a ClusterIP service. This means that the Service is accessible only from within the cluster. There are other types of services like NodePort, LoadBalancer, and ExternalName. But for now, I’ll stick with ClusterIP.\nNow, try to access the ngnix Pod using the Service:\n$ wget -qO- http://10.43.38.173 Note: The IP address is the ClusterIP address of the nginx Service. You can not just copy-paste the IP address from the output above. You need to use the IP address of the nginx Service you got from your local machine’s kubectl get svc command.\nYou should get the default Nginx page. The Service abstracts the Pod IP addresses. Now, kill a nginx Pod and try to access the Service:\n$ kubectl delete pod nginx-676b6c5bbc-zbwl5 pod \"nginx-676b6c5bbc-zbwl5\" deleted If you run the wget command again, you should get the default Nginx page. The Service ensures that the traffic is routed to the available Pods. When I killed a Pod, the K8s immediately created a new one. The Service is still routing traffic to the available Pods. The Service is a stable endpoint for your application.\nNotice that if you delete and recreate the Service, the Service will get a new IP. Again, you must use the new IP address to access the Service. However, the good side is that inside the cluster, you can always use the Service’s name to access it. For example, you can run the following command from the busybox Pod:\n$ wget -qO- http://nginx This command will work even if you delete and recreate the Service. You can rely on this. The Service name is a stable endpoint for your application.\nHorizontal Pod Autoscaler The Horizontal Pod Autoscaler(HPA) is a K8s component that automatically scales the number of Pods in a Deployment based on some metrics. The HPA is a powerful tool for managing the load on your application. Let’s see how it works.\nFirst, I need to have the metrics server on my K8s cluster. Let’s check:\n$ kubectl get deployments -A NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE default nginx 1/1 1 1 38h kube-system coredns 1/1 1 1 6d15h kube-system local-path-provisioner 1/1 1 1 6d15h kube-system metrics-server 1/1 1 1 6d15h kube-system traefik 1/1 1 1 6d15h The metrics-server is running. It means that I can use the HPA. Now, let’s create a HPA for the nginx Deployment:\n$ kubectl autoscale deployment nginx --max 5 --min 2 --cpu-percent 20 horizontalpodautoscaler.autoscaling/nginx autoscaled The above command creates an HPA for the nginx Deployment. Based on CPU usage, the HPA will scale the number of Pods between 2 and 5. If the CPU usage is above 20%, the HPA adds more Pods. If the CPU usage is below 20%, the HPA removes Pods.\nLet’s see the HPA:\nkubectl get hpa NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE nginx Deployment/nginx cpu: /20% 2 5 2 56s The above output shows the HPA for the nginx Deployment. The HPA targets CPU usage and will scale the number of Pods between 2 and 5. The current number of Pods is 2.\nThe current CPU usage is unknown. The reason is that I did not have any CPU constraints. Before I show how HPA works, I should put some constraints on the Pods. I’ll limit the CPU usage of the nginx Pods. I’ll set the CPU limit to 10m for the nginx container:\n$ kubectl set resources deployment nginx --limits=cpu=10m deployment.apps/nginx resources updated In K8s terms, 10m means 10 millicores. It is a fraction of a CPU core. Now, let’s generate some load on the nginx Deployment(do this from busybox Pod):\n$ while true; do wget -q -O- http://nginx; done Let’s observe the HPA:\n$ kubectl get hpa --watch NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE nginx Deployment/nginx cpu: 15%/20% 2 5 2 13m nginx Deployment/nginx cpu: 35%/20% 2 5 2 13m nginx Deployment/nginx cpu: 95%/20% 2 5 4 14m nginx Deployment/nginx cpu: 90%/20% 2 5 5 14m nginx Deployment/nginx cpu: 77%/20% 2 5 5 14m nginx Deployment/nginx cpu: 74%/20% 2 5 5 14m Notice that the HPA is scaling the number of Pods based on the CPU usage. When the CPU usage is above 20%, and the HPA adds more Pods.\nStop the load generation; do Ctrl+C in the busy box Pod. The HPA will scale down the number of Pods:\n$ kubectl get hpa --watch NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE nginx Deployment/nginx cpu: 90%/20% 2 5 5 14m nginx Deployment/nginx cpu: 77%/20% 2 5 5 14m nginx Deployment/nginx cpu: 74%/20% 2 5 5 14m nginx Deployment/nginx cpu: 78%/20% 2 5 5 15m nginx Deployment/nginx cpu: 74%/20% 2 5 5 15m nginx Deployment/nginx cpu: 70%/20% 2 5 5 15m nginx Deployment/nginx cpu: 50%/20% 2 5 5 15m nginx Deployment/nginx cpu: 6%/20% 2 5 5 16m nginx Deployment/nginx cpu: 0%/20% 2 5 5 16m nginx Deployment/nginx cpu: 0%/20% 2 5 5 20m nginx Deployment/nginx cpu: 0%/20% 2 5 2 21m The HPA scaled down the number of Pods. When the CPU usage is below 20%, the HPA removes Pods. As you can see, it took some time to scale down the Pods. The HPA has a cooldown period. It waits for some time before it scales down the Pods. The cooldown period is needed to prevent flapping. The HPA will not scale down the Pods immediately. It waits for some time to see if the CPU usage is stable. There is a cooldown period, or stabilization window, for scaling down and scaling up. The default cooldown for scaling down is 5 minutes. The default cooldown for scaling up is 0 minutes(immediate).\nWrapping Up In this post, I showed you some basic K8s Services and Horizontal Pod Autoscaler concepts. I did not get into details. I just scratched the surface. I used a lot of kubectl to interact with the K8s cluster. Knowing how to use kubectl is essential for working with K8s. It helps you to deploy, manage, and scale your application. You can use it to debug and troubleshoot your application, too. That is something that every developer needs to know. In the next post, I’ll go deeper into kubectl and show you how you can use it to get more information about your application in K8s. Stay tuned.\n","wordCount":"1609","inLanguage":"en","image":"https://rnemet.dev/images/k8s_intro_svc_hpa.png","datePublished":"2025-02-06T20:46:44+02:00","dateModified":"2025-02-06T20:46:44+02:00","author":{"@type":"Person","name":"Robert Nemet"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://rnemet.dev/posts/practical_k8s/k8s_intro_svc_hpa/"},"publisher":{"@type":"Organization","name":"DevCube","logo":{"@type":"ImageObject","url":"https://rnemet.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rnemet.dev/ accesskey=h title="Home (Alt + H)"><img src=https://rnemet.dev/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rnemet.dev/posts/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://rnemet.dev/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://rnemet.dev/posts/practical_k8s/ title="Practical k8s"><span>Practical k8s</span></a></li><li><a href=https://rnemet.dev/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://rnemet.dev/about/ title="About Me"><span>About Me</span></a></li><li><a href=https://rnemet.dev/ title><span></span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Kubernetes: Exposing Services and Horizontal Pod Autoscaler</h1><div class=post-description></div><div class=post-meta><span title='2025-02-06 20:46:44 +0200 +0200'>February 6, 2025</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Robert Nemet</div></header><figure class=entry-cover><img loading=lazy src=https://rnemet.dev/images/k8s_intro_svc_hpa.png alt></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#exposing-deployments-services aria-label="Exposing Deployments: Services">Exposing Deployments: Services</a></li><li><a href=#horizontal-pod-autoscaler aria-label="Horizontal Pod Autoscaler">Horizontal Pod Autoscaler</a></li><li><a href=#wrapping-up aria-label="Wrapping Up">Wrapping Up</a></li></ul></div></details></div><div class=post-content><p>This post is the third part of the series about Kubernetes for beginners. In the
<a href=/practical_k8s/k8s_intro_pt2>second part</a>, I introduced the K8s and its basic
components. In the second part, I discussed containers, pods, and deployments.
This post will discuss services(SVC) and horizontal pod autoscaler(HPA).</p><hr><p>In this short post, I will discuss how to expose your services to the outside world
and scale your applications based on the load.</p><h2 id=exposing-deployments-services>Exposing Deployments: Services<a hidden class=anchor aria-hidden=true href=#exposing-deployments-services>#</a></h2><p>When you create a Deployment, you&rsquo;ll get Pods running your app. So, start local K8s
cluster and deploy an app:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl create deployment nginx --image<span style=color:#f92672>=</span>nginx
</span></span></code></pre></div><p>The above command will create a Deployment named <code>nginx</code> with a single Pod running the
<code>nginx</code> image. You can check the status of Deployment and Pods:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get deployments
</span></span><span style=display:flex><span>NAME    READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>nginx   1/1     <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>1</span>           4m8s
</span></span></code></pre></div><p>The above line tells you that Deployment <code>nginx</code> has one Pod running and is up-to-date.
Now, let&rsquo;s check Pods:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pods
</span></span><span style=display:flex><span>NAME                     READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>nginx-676b6c5bbc-qzxsh   1/1     Running   <span style=color:#ae81ff>0</span>          6m22s
</span></span></code></pre></div><p>Now, add one more Pod:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl run busybox --image busybox --restart<span style=color:#f92672>=</span>Never --rm -it -- sh
</span></span></code></pre></div><p>I&rsquo;m adding a Pod named <code>busybox</code> with the <code>busybox</code> image. I want to use this Pod
to test the connection to the <code>nginx</code> Pod. The above command creates a Pod, runs
a shell, and removes the Pod when you exit the shell. Before I test the connection,
open a new terminal and run the following:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pods -o wide
</span></span><span style=display:flex><span>NAME                     READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>busybox                  1/1     Running   <span style=color:#ae81ff>0</span>          2m16s   10.42.0.63   lima-k3s   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>nginx-676b6c5bbc-qzxsh   1/1     Running   <span style=color:#ae81ff>0</span>          43m     10.42.0.60   lima-k3s   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div><p>Using the output <code>wide</code> option, you can see the IP addresses of the Pods. Now you
see each Pod has its IP address. Go back to the first terminal(busybox) and run:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ wget -qO- http://10.42.0.60
</span></span></code></pre></div><p>You should get a response from the <code>nginx</code> Pod. It should be the default Nginx page.
Now let&rsquo;s kill the nginx Pod:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl delete pod nginx-676b6c5bbc-qzxsh
</span></span><span style=display:flex><span>pod <span style=color:#e6db74>&#34;nginx-676b6c5bbc-qzxsh&#34;</span> deleted
</span></span></code></pre></div><p>If you run the <code>wget</code> command again, you&rsquo;ll get an error. The Pod is gone. Recheck Pods:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get pods -o wide
</span></span><span style=display:flex><span>NAME                     READY   STATUS    RESTARTS   AGE     IP           NODE       NOMINATED NODE   READINESS GATES
</span></span><span style=display:flex><span>busybox                  1/1     Running   <span style=color:#ae81ff>0</span>          8m49s   10.42.0.63   lima-k3s   &lt;none&gt;           &lt;none&gt;
</span></span><span style=display:flex><span>nginx-676b6c5bbc-zbwl5   1/1     Running   <span style=color:#ae81ff>0</span>          2m4s    10.42.0.64   lima-k3s   &lt;none&gt;           &lt;none&gt;
</span></span></code></pre></div><p>Notice several things:</p><ul><li>The old Pod is gone(nginx-676b6c5bbc-qzxsh). A new Pod(nginx-676b6c5bbc-zbwl5) replaces the old one.</li><li>The new Pod has a different IP address.</li><li>Deployment ensures that the desired number of Pods is running. If a Pod dies,
it creates a new one.</li></ul><p>So, if I want to call <code>nginx</code> again, I need to know its new IP. I need something
to abstract the Pod IP addresses. For this purpose, I&rsquo;ll use K8s Services. K8s
Service is a K8s component(resource) for exposing one or more Pods. You can think
of it as a load balancer for your Pods. Let&rsquo;s create a Service for the <code>nginx</code> Deployment:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl expose deployment nginx --port <span style=color:#ae81ff>80</span>
</span></span><span style=display:flex><span>service/nginx exposed
</span></span></code></pre></div><p>Explore services:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get svc
</span></span><span style=display:flex><span>NAME         TYPE        CLUSTER-IP     EXTERNAL-IP   PORT<span style=color:#f92672>(</span>S<span style=color:#f92672>)</span>   AGE
</span></span><span style=display:flex><span>kubernetes   ClusterIP   10.43.0.1      &lt;none&gt;        443/TCP   5d2h
</span></span><span style=display:flex><span>nginx        ClusterIP   10.43.38.173   &lt;none&gt;        80/TCP    30s
</span></span></code></pre></div><p>The above output shows two services: <code>kubernetes</code> and <code>nginx</code>. The <code>kubernetes</code>
Service is a default service for the K8s cluster. The <code>nginx</code> service is the one
I created. It has a ClusterIP address and listens on port 80. The <code>nginx</code> service
is a ClusterIP service. This means that the Service is accessible only from within
the cluster. There are other types of services like NodePort, LoadBalancer, and ExternalName.
But for now, I&rsquo;ll stick with ClusterIP.</p><p>Now, try to access the <code>ngnix</code> Pod using the Service:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ wget -qO- http://10.43.38.173
</span></span></code></pre></div><blockquote><p>Note: The IP address is the ClusterIP address of the <code>nginx</code> Service. You can not just
copy-paste the IP address from the output above. You need to use the IP address of the
<code>nginx</code> Service you got from your local machine&rsquo;s <code>kubectl get svc</code> command.</p></blockquote><p>You should get the default Nginx page. The Service abstracts the Pod IP addresses.
Now, kill a <code>nginx</code> Pod and try to access the Service:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl delete pod nginx-676b6c5bbc-zbwl5
</span></span><span style=display:flex><span>pod <span style=color:#e6db74>&#34;nginx-676b6c5bbc-zbwl5&#34;</span> deleted
</span></span></code></pre></div><p>If you run the <code>wget</code> command again, you should get the default Nginx page. The
Service ensures that the traffic is routed to the available Pods. When I killed
a Pod, the K8s immediately created a new one. The Service is still routing traffic
to the available Pods. The Service is a stable endpoint for your application.</p><p>Notice that if you delete and recreate the Service, the Service will get a new IP.
Again, you must use the new IP address to access the Service. However, the good
side is that inside the cluster, you can always use the Service&rsquo;s name to access
it. For example, you can run the following command from the <code>busybox</code> Pod:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ wget -qO- http://nginx
</span></span></code></pre></div><p>This command will work even if you delete and recreate the Service. You can rely
on this. The Service name is a stable endpoint for your application.</p><h2 id=horizontal-pod-autoscaler>Horizontal Pod Autoscaler<a hidden class=anchor aria-hidden=true href=#horizontal-pod-autoscaler>#</a></h2><p>The Horizontal Pod Autoscaler(HPA) is a K8s component that automatically scales
the number of Pods in a Deployment based on some metrics. The HPA is a powerful
tool for managing the load on your application. Let&rsquo;s see how it works.</p><p>First, I need to have the metrics server on my K8s cluster. Let&rsquo;s check:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get deployments -A
</span></span><span style=display:flex><span>NAMESPACE     NAME                     READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>default       nginx                    1/1     <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>1</span>           38h
</span></span><span style=display:flex><span>kube-system   coredns                  1/1     <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>1</span>           6d15h
</span></span><span style=display:flex><span>kube-system   local-path-provisioner   1/1     <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>1</span>           6d15h
</span></span><span style=display:flex><span>kube-system   metrics-server           1/1     <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>1</span>           6d15h
</span></span><span style=display:flex><span>kube-system   traefik                  1/1     <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>1</span>           6d15h
</span></span></code></pre></div><p>The <code>metrics-server</code> is running. It means that I can use the HPA. Now, let&rsquo;s create
a HPA for the <code>nginx</code> Deployment:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl autoscale deployment nginx --max <span style=color:#ae81ff>5</span> --min <span style=color:#ae81ff>2</span> --cpu-percent <span style=color:#ae81ff>20</span>
</span></span><span style=display:flex><span>horizontalpodautoscaler.autoscaling/nginx autoscaled
</span></span></code></pre></div><p>The above command creates an HPA for the <code>nginx</code> Deployment. Based on CPU usage,
the HPA will scale the number of Pods between 2 and 5. If the CPU usage is above 20%,
the HPA adds more Pods. If the CPU usage is below 20%, the HPA removes Pods.</p><p>Let&rsquo;s see the HPA:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl get hpa
</span></span><span style=display:flex><span>NAME    REFERENCE          TARGETS              MINPODS   MAXPODS   REPLICAS   AGE
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: &lt;unknown&gt;/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>2</span>          56s
</span></span></code></pre></div><p>The above output shows the HPA for the <code>nginx</code> Deployment. The HPA targets CPU usage
and will scale the number of Pods between 2 and 5. The current number of Pods is 2.</p><p>The current CPU usage is unknown. The reason is that I did not have any CPU constraints.
Before I show how HPA works, I should put some constraints on the Pods. I&rsquo;ll limit
the CPU usage of the <code>nginx</code> Pods. I&rsquo;ll set the CPU limit to 10m for the <code>nginx</code> container:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl set resources deployment nginx --limits<span style=color:#f92672>=</span>cpu<span style=color:#f92672>=</span>10m
</span></span><span style=display:flex><span>deployment.apps/nginx resources updated
</span></span></code></pre></div><p>In K8s terms, <code>10m</code> means 10 millicores. It is a fraction of a CPU core. Now, let&rsquo;s
generate some load on the <code>nginx</code> Deployment(do this from busybox Pod):</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ <span style=color:#66d9ef>while</span> true; <span style=color:#66d9ef>do</span> wget -q -O- http://nginx; <span style=color:#66d9ef>done</span>
</span></span></code></pre></div><p>Let&rsquo;s observe the HPA:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get hpa --watch
</span></span><span style=display:flex><span>NAME    REFERENCE          TARGETS        MINPODS   MAXPODS   REPLICAS   AGE
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 15%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>2</span>          13m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 35%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>2</span>          13m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 95%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>4</span>          14m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 90%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          14m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 77%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          14m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 74%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          14m
</span></span></code></pre></div><p>Notice that the HPA is scaling the number of Pods based on the CPU usage. When the
CPU usage is above 20%, and the HPA adds more Pods.</p><p>Stop the load generation; do <code>Ctrl+C</code> in the busy box Pod. The HPA will scale down
the number of Pods:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>$ kubectl get hpa --watch
</span></span><span style=display:flex><span>NAME    REFERENCE          TARGETS        MINPODS   MAXPODS   REPLICAS   AGE
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 90%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          14m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 77%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          14m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 74%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          14m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 78%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          15m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 74%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          15m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 70%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          15m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 50%/20%   <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          15m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 6%/20%    <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          16m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 0%/20%    <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          16m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 0%/20%    <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>5</span>          20m
</span></span><span style=display:flex><span>nginx   Deployment/nginx   cpu: 0%/20%    <span style=color:#ae81ff>2</span>         <span style=color:#ae81ff>5</span>         <span style=color:#ae81ff>2</span>          21m
</span></span></code></pre></div><p>The HPA scaled down the number of Pods. When the CPU usage is below 20%, the HPA
removes Pods. As you can see, it took some time to scale down the Pods. The HPA
has a cooldown period. It waits for some time before it scales down the Pods. The
cooldown period is needed to prevent flapping. The HPA will not scale down the Pods
immediately. It waits for some time to see if the CPU usage is stable. There is a
cooldown period, or stabilization window, for scaling down and scaling up. The default
cooldown for scaling down is 5 minutes. The default cooldown for scaling up is 0 minutes(immediate).</p><h2 id=wrapping-up>Wrapping Up<a hidden class=anchor aria-hidden=true href=#wrapping-up>#</a></h2><p>In this post, I showed you some basic K8s Services and Horizontal Pod Autoscaler
concepts. I did not get into details. I just scratched the surface. I used a lot of
<code>kubectl</code> to interact with the K8s cluster. Knowing how to use <code>kubectl</code> is essential
for working with K8s. It helps you to deploy, manage, and scale your application.
You can use it to debug and troubleshoot your application, too. That is something
that every developer needs to know. In <a href=/practical_k8s/k8s_intro_pt4>the next post</a>, I&rsquo;ll go deeper into <code>kubectl</code>
and show you how you can use it to get more information about your application in K8s.
Stay tuned.</p><div class=subscribe><iframe src=https://rnemet.substack.com/embed width=480 height=320 style="border:1px solid #eee;background:#fff;margin:auto;display:block" frameborder=0 scrolling=no></iframe></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://rnemet.dev/tags/k8s/>K8s</a></li><li><a href=https://rnemet.dev/tags/kubernetes/>Kubernetes</a></li><li><a href=https://rnemet.dev/tags/basics/>Basics</a></li><li><a href=https://rnemet.dev/tags/services/>Services</a></li><li><a href=https://rnemet.dev/tags/hpa/>Hpa</a></li><li><a href=https://rnemet.dev/tags/scaling/>Scaling</a></li></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes: Exposing Services and Horizontal Pod Autoscaler on x" href="https://x.com/intent/tweet/?text=Kubernetes%3a%20Exposing%20Services%20and%20Horizontal%20Pod%20Autoscaler&amp;url=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_svc_hpa%2f&amp;hashtags=k8s%2ckubernetes%2cbasics%2cservices%2chpa%2cscaling"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes: Exposing Services and Horizontal Pod Autoscaler on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_svc_hpa%2f&amp;title=Kubernetes%3a%20Exposing%20Services%20and%20Horizontal%20Pod%20Autoscaler&amp;summary=Kubernetes%3a%20Exposing%20Services%20and%20Horizontal%20Pod%20Autoscaler&amp;source=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_svc_hpa%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes: Exposing Services and Horizontal Pod Autoscaler on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_svc_hpa%2f&title=Kubernetes%3a%20Exposing%20Services%20and%20Horizontal%20Pod%20Autoscaler"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes: Exposing Services and Horizontal Pod Autoscaler on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_svc_hpa%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes: Exposing Services and Horizontal Pod Autoscaler on whatsapp" href="https://api.whatsapp.com/send?text=Kubernetes%3a%20Exposing%20Services%20and%20Horizontal%20Pod%20Autoscaler%20-%20https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_svc_hpa%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes: Exposing Services and Horizontal Pod Autoscaler on telegram" href="https://telegram.me/share/url?text=Kubernetes%3a%20Exposing%20Services%20and%20Horizontal%20Pod%20Autoscaler&amp;url=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_svc_hpa%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes: Exposing Services and Horizontal Pod Autoscaler on ycombinator" href="https://news.ycombinator.com/submitlink?t=Kubernetes%3a%20Exposing%20Services%20and%20Horizontal%20Pod%20Autoscaler&u=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_svc_hpa%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://rnemet.dev/>DevCube</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>