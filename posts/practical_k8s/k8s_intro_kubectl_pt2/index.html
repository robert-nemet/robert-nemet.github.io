<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Kubernetes tools: Kubectl Part 2 | DevCube</title>
<meta name=keywords content="k8s,kubernetes,basics,kubectl"><meta name=description content="This post is the fifth part of the series about Kubernetes for beginners. In the
fourth part, I started to write about the Kubernetes
Swiss army knife: kubectl. I covered ways how to find the components you are looking
for. In this episode, I&rsquo;ll show you how you can gather more information about Kubernetes
components, focusing on status and logs. This can be useful when debugging your
application and trying to figure out what&rsquo;s going on."><meta name=author content="Robert Nemet"><link rel=canonical href=https://rnemet.dev/posts/practical_k8s/k8s_intro_kubectl_pt2/><link crossorigin=anonymous href=/assets/css/stylesheet.d6fcd20a4fb86efa4dfac8ec95da60244cc8871042183da1ef28e3a762ad79c8.css integrity="sha256-1vzSCk+4bvpN+sjsldpgJEzIhxBCGD2h7yjjp2Ktecg=" rel="preload stylesheet" as=style><link rel=icon href=https://rnemet.dev/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://rnemet.dev/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://rnemet.dev/favicon-32x32.png><link rel=apple-touch-icon href=https://rnemet.dev/apple-touch-icon.png><link rel=mask-icon href=https://rnemet.dev/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://rnemet.dev/posts/practical_k8s/k8s_intro_kubectl_pt2/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-L148RQBR36"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-L148RQBR36")}</script><meta property="og:url" content="https://rnemet.dev/posts/practical_k8s/k8s_intro_kubectl_pt2/"><meta property="og:site_name" content="DevCube"><meta property="og:title" content="Kubernetes tools: Kubectl Part 2"><meta property="og:description" content="This post is the fifth part of the series about Kubernetes for beginners. In the fourth part, I started to write about the Kubernetes Swiss army knife: kubectl. I covered ways how to find the components you are looking for. In this episode, I’ll show you how you can gather more information about Kubernetes components, focusing on status and logs. This can be useful when debugging your application and trying to figure out what’s going on."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-03-03T19:23:56+01:00"><meta property="article:modified_time" content="2025-03-03T19:23:56+01:00"><meta property="article:tag" content="K8s"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Basics"><meta property="article:tag" content="Kubectl"><meta property="og:image" content="https://rnemet.dev/images/k8s_intro_local_and_kubectl.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://rnemet.dev/images/k8s_intro_local_and_kubectl.png"><meta name=twitter:title content="Kubernetes tools: Kubectl Part 2"><meta name=twitter:description content="This post is the fifth part of the series about Kubernetes for beginners. In the
fourth part, I started to write about the Kubernetes
Swiss army knife: kubectl. I covered ways how to find the components you are looking
for. In this episode, I&rsquo;ll show you how you can gather more information about Kubernetes
components, focusing on status and logs. This can be useful when debugging your
application and trying to figure out what&rsquo;s going on."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://rnemet.dev/posts/"},{"@type":"ListItem","position":2,"name":"Practical Kubernetes","item":"https://rnemet.dev/posts/practical_k8s/"},{"@type":"ListItem","position":3,"name":"Kubernetes tools: Kubectl Part 2","item":"https://rnemet.dev/posts/practical_k8s/k8s_intro_kubectl_pt2/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Kubernetes tools: Kubectl Part 2","name":"Kubernetes tools: Kubectl Part 2","description":"This post is the fifth part of the series about Kubernetes for beginners. In the fourth part, I started to write about the Kubernetes Swiss army knife: kubectl. I covered ways how to find the components you are looking for. In this episode, I\u0026rsquo;ll show you how you can gather more information about Kubernetes components, focusing on status and logs. This can be useful when debugging your application and trying to figure out what\u0026rsquo;s going on.\n","keywords":["k8s","kubernetes","basics","kubectl"],"articleBody":"This post is the fifth part of the series about Kubernetes for beginners. In the fourth part, I started to write about the Kubernetes Swiss army knife: kubectl. I covered ways how to find the components you are looking for. In this episode, I’ll show you how you can gather more information about Kubernetes components, focusing on status and logs. This can be useful when debugging your application and trying to figure out what’s going on.\nLet’s start…\nThe last time I created some Deployment with kubectl, I used the following command:\n❯ kubectl create deployment nginx --image=nginx As well, I created a Pod with the following command:\n❯ kubectl run nginx --image=nginx At the end of the previous post, I showed you how to see those resources’ manifests. For example, for the Pod:\n❯ kubectl get pod nginx -o yaml Describing Resources The most interesting part is the status of the Pod. You can check that by looking at the status tag from the previous command’s output:\nstatus: conditions: - lastProbeTime: null lastTransitionTime: \"2025-03-03T18:22:32Z\" status: \"True\" type: PodReadyToStartContainers - lastProbeTime: null lastTransitionTime: \"2025-02-19T21:02:51Z\" status: \"True\" type: Initialized - lastProbeTime: null lastTransitionTime: \"2025-03-03T18:22:32Z\" status: \"True\" type: Ready - lastProbeTime: null lastTransitionTime: \"2025-03-03T18:22:32Z\" status: \"True\" type: ContainersReady - lastProbeTime: null lastTransitionTime: \"2025-02-19T21:02:51Z\" status: \"True\" type: PodScheduled containerStatuses: - containerID: docker://c4c6f639d1569c84dae2188d3c99cb4164a5bade4d1f402f622edeccb69e2dd6 image: nginx:latest imageID: docker-pullable://nginx@sha256:9d6b58feebd2dbd3c56ab5853333d627cc6e281011cfd6050fa4bcf2072c9496 lastState: terminated: containerID: docker://05b8a06f19bcba31e905ebe54ca995e88f9dd43899d7ff2a48c1505fb96663c0 exitCode: 0 finishedAt: \"2025-02-20T21:51:42Z\" reason: Completed startedAt: \"2025-02-20T20:27:29Z\" name: nginx ready: true restartCount: 3 started: true state: running: startedAt: \"2025-03-03T18:22:32Z\" volumeMounts: - mountPath: /var/run/secrets/kubernetes.io/serviceaccount name: kube-api-access-lwtpw readOnly: true recursiveReadOnly: Disabled hostIP: 192.168.5.15 hostIPs: - ip: 192.168.5.15 phase: Running podIP: 10.42.0.58 podIPs: - ip: 10.42.0.58 qosClass: BestEffort startTime: \"2025-02-19T21:02:51Z\" As you can see, it is long and not so human-friendly. You can see some interesting stuff there, but you need more readable output with more details and relevant information. This format, yaml or the json format, is suitable if you push it to some application.\nFor us humans, it is better to use the describe command:\n❯ kubectl describe pod nginx Name: nginx Namespace: default Priority: 0 Service Account: default Node: lima-rancher-desktop/192.168.5.15 Start Time: Wed, 19 Feb 2025 22:02:51 +0100 Labels: run=nginx Annotations: Status: Running IP: 10.42.0.58 IPs: IP: 10.42.0.58 Containers: nginx: Container ID: docker://c4c6f639d1569c84dae2188d3c99cb4164a5bade4d1f402f622edeccb69e2dd6 Image: nginx Image ID: docker-pullable://nginx@sha256:9d6b58feebd2dbd3c56ab5853333d627cc6e281011cfd6050fa4bcf2072c9496 Port: Host Port: State: Running Started: Mon, 03 Mar 2025 19:22:32 +0100 Last State: Terminated Reason: Completed Exit Code: 0 Started: Thu, 20 Feb 2025 21:27:29 +0100 Finished: Thu, 20 Feb 2025 22:51:42 +0100 Ready: True Restart Count: 3 Environment: Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lwtpw (ro) Conditions: Type Status PodReadyToStartContainers True Initialized True Ready True ContainersReady True PodScheduled True Volumes: kube-api-access-lwtpw: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: DownwardAPI: true QoS Class: BestEffort Node-Selectors: Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal SandboxChanged 28m kubelet Pod sandbox changed, it will be killed and re-created. Normal Pulling 28m kubelet Pulling image \"nginx\" Normal Pulled 27m kubelet Successfully pulled image \"nginx\" in 27.484s (27.484s including waiting). Image size: 191998640 bytes. Normal Created 27m kubelet Created container nginx Normal Started 27m kubelet Started container nginx Most of the time, you’ll be looking into:\nevents, so you can see what’s happening with your Pod during scheduling. conditions to understand your Pod’s status. containers, especially their state and previous state. Of course, this depends on the issue you are trying to figure out.\nExample: Wrong Image Let’s create a new Deployment:\n❯ kubectl create deployment my-deployment --image=nginx2 When you execute it, you’ll get messages like: deployment.apps/my-deployment created. So, all sounds good. Let’s check it out:\n❯ k get deployments.apps my-deployment NAME READY UP-TO-DATE AVAILABLE AGE my-deployment 0/1 1 0 85s Ok, it is not been so long. Maybe it needs more time, right? Wait a bit and try again:\n❯ k get deployments.apps my-deployment NAME READY UP-TO-DATE AVAILABLE AGE my-deployment 0/1 1 0 2m42s Ok, now it is time to start panicking… Just joking. In most cases, two minutes should be enough to start a Pod unless something is wrong.\nIn this case, there is something wrong. Let’s try to figure out why. First, we can try to check deployment my-deployment:\n❯ kubectl describe deployment my-deployment But all should be fine there. Let’s check the pods:\n❯ kubectl get pods -l app=my-deployment NAME READY STATUS RESTARTS AGE my-deployment-cd98b4847-4kct6 0/1 ImagePullBackOff 0 5d16h That means the image used for my-deployment cannot be pulled. Let’s check the details of the Pod:\n❯ kubectl describe pod my-deployment-cd98b4847-4kct6 ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 5d16h default-scheduler Successfully assigned default/my-deployment-cd98b4847-4kct6 to lima-rancher-desktop Normal Pulling 5d16h (x4 over 5d16h) kubelet Pulling image \"nginx2\" Warning Failed 5d16h (x4 over 5d16h) kubelet Failed to pull image \"nginx2\": Error response from daemon: pull access denied for nginx2, repository does not exist or may require 'docker login': denied: requested access to the resource is denied Warning Failed 5d16h (x4 over 5d16h) kubelet Error: ErrImagePull Warning Failed 5d16h (x6 over 5d16h) kubelet Error: ImagePullBackOff Normal BackOff 5d16h (x7 over 5d16h) kubelet Back-off pulling image \"nginx2\" Warning FailedMount 17m (x2 over 18m) kubelet MountVolume.SetUp failed for volume \"kube-api-access-kklq6\" : object \"default\"/\"kube-root-ca.crt\" not registered Normal SandboxChanged 17m kubelet Pod sandbox changed, it will be killed and re-created. Normal Pulling 16m (x4 over 17m) kubelet Pulling image \"nginx2\" Warning Failed 15m (x4 over 17m) kubelet Failed to pull image \"nginx2\": Error response from daemon: pull access denied for nginx2, repository does not exist or may require 'docker login': denied: requested access to the resource is denied Warning Failed 15m (x4 over 17m) kubelet Error: ErrImagePull Warning Failed 15m (x5 over 17m) kubelet Error: ImagePullBackOff Normal BackOff 2m56s (x57 over 17m) kubelet Back-off pulling image \"nginx2\" Let’s focus just on the events. We see that the Pod fails to pull the image “nginx2” because it does not exist or may require a ‘docker login’. This is indicated by the warning messages “Failed to pull image” and “Error: ErrImagePull”. Let’s fix it:\n❯ kubectl set image deployment/my-deployment nginx2=nginx:latest deployment.apps/my-deployment image updated Check again:\n❯ kubectl get deployment my-deployment NAME READY UP-TO-DATE AVAILABLE AGE my-deployment 1/1 1 1 5d16h All good now.\nExample: Pod crashing Let’s create a new deployment. Save below in the file and apply it:\napiVersion: apps/v1 kind: Deployment metadata: creationTimestamp: null labels: app: stress name: stress spec: replicas: 1 selector: matchLabels: app: stress template: metadata: labels: app: stress spec: containers: - image: polinux/stress command: - stress args: [\"--vm\", \"1\", \"--vm-bytes\", \"15M\", \"--vm-hang\", \"1\"] name: stress resources: limits: memory: 20Mi requests: memory: 10Mi Wait for the pods to be ready:\n❯ kubectl get pods -w NAME READY STATUS RESTARTS AGE stress-7d6468d54-b6mhb 1/1 Running 1 (22h ago) 22h Now let’s set the memory limit to 10Mi:\n❯ kubectl set resources deployment stress -c stress --limits=memory=10Mi deployment.apps/stress resource requirements updated Check the status:\n❯ kubectl get pods -l app=stress --watch NAME READY STATUS RESTARTS AGE stress-6c9c8f8d6b-98z7d 0/1 OOMKilled 2 (34s ago) 54s stress-7d6468d54-b6mhb 1/1 Running 1 (22h ago) 22h stress-6c9c8f8d6b-98z7d 0/1 CrashLoopBackOff 2 (16s ago) 58s As you can see, the Pod is crashing due to the memory limit being exceeded. Let’s describe it:\n❯ kubectl describe pod stress-6c9c8f8d6b-98z7d Name: stress-6c9c8f8d6b-98z7d Namespace: default Priority: 0 Service Account: default Node: lima-rancher-desktop/192.168.5.15 Start Time: Mon, 10 Mar 2025 20:10:36 +0100 Labels: app=stress pod-template-hash=6c9c8f8d6b Annotations: Status: Running IP: 10.42.0.107 IPs: IP: 10.42.0.107 Controlled By: ReplicaSet/stress-6c9c8f8d6b Containers: stress: Container ID: docker://9b2ecba9c96c87e50229e6780c5817a26d89db095865ad2422a84e8c0a0edaa4 Image: polinux/stress Image ID: docker-pullable://polinux/stress@sha256:b6144f84f9c15dac80deb48d3a646b55c7043ab1d83ea0a697c09097aaad21aa Port: Host Port: Command: stress Args: --vm 1 --vm-bytes 15M --vm-hang 1 State: Waiting Reason: CrashLoopBackOff Last State: Terminated Reason: OOMKilled Exit Code: 1 Started: Mon, 10 Mar 2025 20:12:54 +0100 Finished: Mon, 10 Mar 2025 20:12:54 +0100 Ready: False Restart Count: 4 Limits: memory: 10Mi Requests: memory: 10Mi Environment: Mounts: /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-58ffj (ro) Conditions: Type Status PodReadyToStartContainers True Initialized True Ready False ContainersReady False PodScheduled True Volumes: kube-api-access-58ffj: Type: Projected (a volume that contains injected data from multiple sources) TokenExpirationSeconds: 3607 ConfigMapName: kube-root-ca.crt ConfigMapOptional: DownwardAPI: true QoS Class: Burstable Node-Selectors: Tolerations: node.kubernetes.io/not-ready:NoExecute op=Exists for 300s node.kubernetes.io/unreachable:NoExecute op=Exists for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 2m32s default-scheduler Successfully assigned default/stress-6c9c8f8d6b-98z7d to lima-rancher-desktop Normal Pulled 2m23s kubelet Successfully pulled image \"polinux/stress\" in 9.201s (9.201s including waiting). Image size: 9744175 bytes. Normal Pulled 2m14s kubelet Successfully pulled image \"polinux/stress\" in 9.232s (9.232s including waiting). Image size: 9744175 bytes. Normal Pulled 111s kubelet Successfully pulled image \"polinux/stress\" in 9.254s (9.254s including waiting). Image size: 9744175 bytes. Normal Created 74s (x4 over 2m23s) kubelet Created container stress Normal Started 74s (x4 over 2m23s) kubelet Started container stress Normal Pulled 74s kubelet Successfully pulled image \"polinux/stress\" in 9.237s (9.237s including waiting). Image size: 9744175 bytes. Warning BackOff 37s (x8 over 2m13s) kubelet Back-off restarting failed container stress in pod stress-6c9c8f8d6b-98z7d_default(508f4d6e-5a88-4ccc-b584-a8138dfc9da9) Normal Pulling 24s (x5 over 2m32s) kubelet Pulling image \"polinux/stress\" Focus on this section:\n... Containers: stress: Container ID: docker://9b2ecba9c96c87e50229e6780c5817a26d89db095865ad2422a84e8c0a0edaa4 Image: polinux/stress Image ID: docker-pullable://polinux/stress@sha256:b6144f84f9c15dac80deb48d3a646b55c7043ab1d83ea0a697c09097aaad21aa Port: Host Port: Command: stress Args: --vm 1 --vm-bytes 15M --vm-hang 1 State: Waiting Reason: CrashLoopBackOff Last State: Terminated Reason: OOMKilled Exit Code: 1 Started: Mon, 10 Mar 2025 20:12:54 +0100 Finished: Mon, 10 Mar 2025 20:12:54 +0100 Ready: False Restart Count: 4 ... As you can see, the container is crashing due to an Out Of Memory (OOM) error. This is because the container is trying to allocate more memory than is available on the node. To fix this issue, we should increase the container’s memory request limit.\n❯ kubectl set resources deployment stress -c stress --limits=memory=15Mi deployment.apps/stress resource requirements updated This was intentionally set to be OOMKilled. But sometimes, you can have a case when the container is restarting periodically. You notice that there are sporadical service interruptions, but at first glance, everything is fine. Then, you should check if the Restart Count is greater than 0. For this reason, check the Last State section. There, you can find indications of what is going on.\nIn this case, I only had one container in the Pod. But sometimes, you can have a case when multiple containers are in the Pod. In such cases, you should check the state of all containers.\nMissing configuration Let’s say you have a Deployment like this:\napiVersion: apps/v1 kind: Deployment metadata: labels: app: stress-missing-cm name: stress-cm spec: replicas: 1 selector: matchLabels: app: stress-missing-cm template: metadata: labels: app: stress-missing-cm spec: containers: - image: polinux/stress command: - stress args: [\"--vm\", \"1\", \"--vm-bytes\", \"15M\", \"--vm-hang\", \"1\"] name: stress resources: limits: memory: 20Mi requests: memory: 10Mi env: - name: LOG_LEVEL valueFrom: configMapKeyRef: name: env-config key: log_level Save it on file stress-missing-cm.yaml and apply it with kubectl apply -f stress-missing-cm.yaml. Wait for the pod to be created and check its status with kubectl get pods -l app=stress-missing-cm -w.\n❯ kubectl get deployments stress-cm --watch NAME READY UP-TO-DATE AVAILABLE AGE stress-cm 0/1 1 0 3m5s Ok, let’s check Pods:\n❯ kubectl get pods -l app=stress-cm --watch No pods? What is going on? Now, you can not use kubectl describe to determine what is happening. However, you should know that K8s Deployment does not handle Pods. It actually handles ReplicaSets, which in turn manages Pods. So, let’s look for the right ReplicaSets and figure out what is happening.\n❯ kubectl get replicasets NAME DESIRED CURRENT READY AGE stress-5b9f9dfb49 0 0 0 23m stress-6c9c8f8d6b 0 0 0 22h stress-74946f474c 0 0 0 22h stress-7d6468d54 1 1 1 22h stress-94756c79f 0 0 0 22h stress-94b954f85 0 0 0 22h stress-cm-57d6cdbc9f 1 1 0 6m42s One I’m looking for is stress-cm-57d6cdbc9f. Let’s describe it:\n❯ kubectl describe replicasets stress-cm-57d6cdbc9f Name: stress-cm-57d6cdbc9f Namespace: default Selector: app=stress-missing-cm,pod-template-hash=57d6cdbc9f Labels: app=stress-missing-cm pod-template-hash=57d6cdbc9f Annotations: deployment.kubernetes.io/desired-replicas: 1 deployment.kubernetes.io/max-replicas: 2 deployment.kubernetes.io/revision: 1 Controlled By: Deployment/stress-cm Replicas: 1 current / 1 desired Pods Status: 0 Running / 1 Waiting / 0 Succeeded / 0 Failed Pod Template: Labels: app=stress-missing-cm pod-template-hash=57d6cdbc9f Containers: stress: Image: polinux/stress Port: Host Port: Command: stress Args: --vm 1 --vm-bytes 15M --vm-hang 1 Limits: memory: 20Mi Requests: memory: 10Mi Environment: LOG_LEVEL: ","wordCount":"2708","inLanguage":"en","image":"https://rnemet.dev/images/k8s_intro_local_and_kubectl.png","datePublished":"2025-03-03T19:23:56+01:00","dateModified":"2025-03-03T19:23:56+01:00","author":{"@type":"Person","name":"Robert Nemet"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://rnemet.dev/posts/practical_k8s/k8s_intro_kubectl_pt2/"},"publisher":{"@type":"Organization","name":"DevCube","logo":{"@type":"ImageObject","url":"https://rnemet.dev/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rnemet.dev/ accesskey=h title="Home (Alt + H)"><img src=https://rnemet.dev/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://rnemet.dev/posts/projects/ title=Projects><span>Projects</span></a></li><li><a href=https://rnemet.dev/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://rnemet.dev/posts/practical_k8s/ title="Practical k8s"><span>Practical k8s</span></a></li><li><a href=https://rnemet.dev/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://rnemet.dev/about/ title="About Me"><span>About Me</span></a></li><li><a href=https://rnemet.dev/ title><span></span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Kubernetes tools: Kubectl Part 2</h1><div class=post-description></div><div class=post-meta><span title='2025-03-03 19:23:56 +0100 CET'>March 3, 2025</span>&nbsp;·&nbsp;13 min&nbsp;·&nbsp;Robert Nemet</div></header><figure class=entry-cover><img loading=lazy src=https://rnemet.dev/images/k8s_intro_local_and_kubectl.png alt></figure><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#describing-resources aria-label="Describing Resources">Describing Resources</a><ul><li><a href=#example-wrong-image aria-label="Example: Wrong Image">Example: Wrong Image</a></li><li><a href=#example-pod-crashing aria-label="Example: Pod crashing">Example: Pod crashing</a></li><li><a href=#missing-configuration aria-label="Missing configuration">Missing configuration</a></li><li><a href=#conclusion aria-label=Conclusion>Conclusion</a></li></ul></li><li><a href=#logs aria-label=Logs>Logs</a></li><li><a href=#summary aria-label=Summary>Summary</a></li></ul></div></details></div><div class=post-content><p>This post is the fifth part of the series about Kubernetes for beginners. In the
<a href=/practical_k8s/k8s_intro_pt4>fourth part</a>, I started to write about the Kubernetes
Swiss army knife: <code>kubectl</code>. I covered ways how to find the components you are looking
for. In this episode, I&rsquo;ll show you how you can gather more information about Kubernetes
components, focusing on status and logs. This can be useful when debugging your
application and trying to figure out what&rsquo;s going on.</p><p>Let&rsquo;s start&mldr;</p><hr><p>The last time I created some Deployment with kubectl, I used the following command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl create deployment nginx --image<span style=color:#f92672>=</span>nginx
</span></span></code></pre></div><p>As well, I created a Pod with the following command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl run nginx --image<span style=color:#f92672>=</span>nginx
</span></span></code></pre></div><p>At the end of <a href=/practical_k8s/k8s_intro_pt4>the previous post</a>, I showed you how
to see those resources&rsquo; manifests. For example, for the Pod:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl get pod nginx -o yaml
</span></span></code></pre></div><h2 id=describing-resources>Describing Resources<a hidden class=anchor aria-hidden=true href=#describing-resources>#</a></h2><p>The most interesting part is the status of the Pod. You can check that by looking
at the <code>status</code> tag from the previous command&rsquo;s output:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>status</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>conditions</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>lastProbeTime</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>lastTransitionTime</span>: <span style=color:#e6db74>&#34;2025-03-03T18:22:32Z&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>status</span>: <span style=color:#e6db74>&#34;True&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>type</span>: <span style=color:#ae81ff>PodReadyToStartContainers</span>
</span></span><span style=display:flex><span>  - <span style=color:#f92672>lastProbeTime</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>lastTransitionTime</span>: <span style=color:#e6db74>&#34;2025-02-19T21:02:51Z&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>status</span>: <span style=color:#e6db74>&#34;True&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>type</span>: <span style=color:#ae81ff>Initialized</span>
</span></span><span style=display:flex><span>  - <span style=color:#f92672>lastProbeTime</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>lastTransitionTime</span>: <span style=color:#e6db74>&#34;2025-03-03T18:22:32Z&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>status</span>: <span style=color:#e6db74>&#34;True&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>type</span>: <span style=color:#ae81ff>Ready</span>
</span></span><span style=display:flex><span>  - <span style=color:#f92672>lastProbeTime</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>lastTransitionTime</span>: <span style=color:#e6db74>&#34;2025-03-03T18:22:32Z&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>status</span>: <span style=color:#e6db74>&#34;True&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>type</span>: <span style=color:#ae81ff>ContainersReady</span>
</span></span><span style=display:flex><span>  - <span style=color:#f92672>lastProbeTime</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>lastTransitionTime</span>: <span style=color:#e6db74>&#34;2025-02-19T21:02:51Z&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>status</span>: <span style=color:#e6db74>&#34;True&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>type</span>: <span style=color:#ae81ff>PodScheduled</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>containerStatuses</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>containerID</span>: <span style=color:#ae81ff>docker://c4c6f639d1569c84dae2188d3c99cb4164a5bade4d1f402f622edeccb69e2dd6</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>nginx:latest</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>imageID</span>: <span style=color:#ae81ff>docker-pullable://nginx@sha256:9d6b58feebd2dbd3c56ab5853333d627cc6e281011cfd6050fa4bcf2072c9496</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>lastState</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>terminated</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>containerID</span>: <span style=color:#ae81ff>docker://05b8a06f19bcba31e905ebe54ca995e88f9dd43899d7ff2a48c1505fb96663c0</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>exitCode</span>: <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>finishedAt</span>: <span style=color:#e6db74>&#34;2025-02-20T21:51:42Z&#34;</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>reason</span>: <span style=color:#ae81ff>Completed</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>startedAt</span>: <span style=color:#e6db74>&#34;2025-02-20T20:27:29Z&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nginx</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>ready</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>restartCount</span>: <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>started</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>state</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>running</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>startedAt</span>: <span style=color:#e6db74>&#34;2025-03-03T18:22:32Z&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>volumeMounts</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>mountPath</span>: <span style=color:#ae81ff>/var/run/secrets/kubernetes.io/serviceaccount</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>name</span>: <span style=color:#ae81ff>kube-api-access-lwtpw</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>readOnly</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>recursiveReadOnly</span>: <span style=color:#ae81ff>Disabled</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>hostIP</span>: <span style=color:#ae81ff>192.168.5.15</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>hostIPs</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>ip</span>: <span style=color:#ae81ff>192.168.5.15</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>phase</span>: <span style=color:#ae81ff>Running</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>podIP</span>: <span style=color:#ae81ff>10.42.0.58</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>podIPs</span>:
</span></span><span style=display:flex><span>  - <span style=color:#f92672>ip</span>: <span style=color:#ae81ff>10.42.0.58</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>qosClass</span>: <span style=color:#ae81ff>BestEffort</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>startTime</span>: <span style=color:#e6db74>&#34;2025-02-19T21:02:51Z&#34;</span>
</span></span></code></pre></div><p>As you can see, it is long and not so human-friendly. You can see some interesting
stuff there, but you need more readable output with more details and relevant information.
This format, <code>yaml</code> or the <code>json</code> format, is suitable if you push it to some application.</p><p>For us humans, it is better to use the <code>describe</code> command:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl describe pod nginx
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Name:             nginx
</span></span><span style=display:flex><span>Namespace:        default
</span></span><span style=display:flex><span>Priority:         <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>Service Account:  default
</span></span><span style=display:flex><span>Node:             lima-rancher-desktop/192.168.5.15
</span></span><span style=display:flex><span>Start Time:       Wed, <span style=color:#ae81ff>19</span> Feb <span style=color:#ae81ff>2025</span> 22:02:51 +0100
</span></span><span style=display:flex><span>Labels:           run<span style=color:#f92672>=</span>nginx
</span></span><span style=display:flex><span>Annotations:      &lt;none&gt;
</span></span><span style=display:flex><span>Status:           Running
</span></span><span style=display:flex><span>IP:               10.42.0.58
</span></span><span style=display:flex><span>IPs:
</span></span><span style=display:flex><span>  IP:  10.42.0.58
</span></span><span style=display:flex><span>Containers:
</span></span><span style=display:flex><span>  nginx:
</span></span><span style=display:flex><span>    Container ID:   docker://c4c6f639d1569c84dae2188d3c99cb4164a5bade4d1f402f622edeccb69e2dd6
</span></span><span style=display:flex><span>    Image:          nginx
</span></span><span style=display:flex><span>    Image ID:       docker-pullable://nginx@sha256:9d6b58feebd2dbd3c56ab5853333d627cc6e281011cfd6050fa4bcf2072c9496
</span></span><span style=display:flex><span>    Port:           &lt;none&gt;
</span></span><span style=display:flex><span>    Host Port:      &lt;none&gt;
</span></span><span style=display:flex><span>    State:          Running
</span></span><span style=display:flex><span>      Started:      Mon, <span style=color:#ae81ff>03</span> Mar <span style=color:#ae81ff>2025</span> 19:22:32 +0100
</span></span><span style=display:flex><span>    Last State:     Terminated
</span></span><span style=display:flex><span>      Reason:       Completed
</span></span><span style=display:flex><span>      Exit Code:    <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>      Started:      Thu, <span style=color:#ae81ff>20</span> Feb <span style=color:#ae81ff>2025</span> 21:27:29 +0100
</span></span><span style=display:flex><span>      Finished:     Thu, <span style=color:#ae81ff>20</span> Feb <span style=color:#ae81ff>2025</span> 22:51:42 +0100
</span></span><span style=display:flex><span>    Ready:          True
</span></span><span style=display:flex><span>    Restart Count:  <span style=color:#ae81ff>3</span>
</span></span><span style=display:flex><span>    Environment:    &lt;none&gt;
</span></span><span style=display:flex><span>    Mounts:
</span></span><span style=display:flex><span>      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-lwtpw <span style=color:#f92672>(</span>ro<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>Conditions:
</span></span><span style=display:flex><span>  Type                        Status
</span></span><span style=display:flex><span>  PodReadyToStartContainers   True
</span></span><span style=display:flex><span>  Initialized                 True
</span></span><span style=display:flex><span>  Ready                       True
</span></span><span style=display:flex><span>  ContainersReady             True
</span></span><span style=display:flex><span>  PodScheduled                True
</span></span><span style=display:flex><span>Volumes:
</span></span><span style=display:flex><span>  kube-api-access-lwtpw:
</span></span><span style=display:flex><span>    Type:                    Projected <span style=color:#f92672>(</span>a volume that contains injected data from multiple sources<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    TokenExpirationSeconds:  <span style=color:#ae81ff>3607</span>
</span></span><span style=display:flex><span>    ConfigMapName:           kube-root-ca.crt
</span></span><span style=display:flex><span>    ConfigMapOptional:       &lt;nil&gt;
</span></span><span style=display:flex><span>    DownwardAPI:             true
</span></span><span style=display:flex><span>QoS Class:                   BestEffort
</span></span><span style=display:flex><span>Node-Selectors:              &lt;none&gt;
</span></span><span style=display:flex><span>Tolerations:                 node.kubernetes.io/not-ready:NoExecute op<span style=color:#f92672>=</span>Exists <span style=color:#66d9ef>for</span> 300s
</span></span><span style=display:flex><span>                             node.kubernetes.io/unreachable:NoExecute op<span style=color:#f92672>=</span>Exists <span style=color:#66d9ef>for</span> 300s
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type    Reason          Age   From     Message
</span></span><span style=display:flex><span>  ----    ------          ----  ----     -------
</span></span><span style=display:flex><span>  Normal  SandboxChanged  28m   kubelet  Pod sandbox changed, it will be killed and re-created.
</span></span><span style=display:flex><span>  Normal  Pulling         28m   kubelet  Pulling image <span style=color:#e6db74>&#34;nginx&#34;</span>
</span></span><span style=display:flex><span>  Normal  Pulled          27m   kubelet  Successfully pulled image <span style=color:#e6db74>&#34;nginx&#34;</span> in 27.484s <span style=color:#f92672>(</span>27.484s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>191998640</span> bytes.
</span></span><span style=display:flex><span>  Normal  Created         27m   kubelet  Created container nginx
</span></span><span style=display:flex><span>  Normal  Started         27m   kubelet  Started container nginx
</span></span></code></pre></div><p>Most of the time, you&rsquo;ll be looking into:</p><ul><li>events, so you can see what&rsquo;s happening with your Pod during scheduling.</li><li>conditions to understand your Pod&rsquo;s status.</li><li>containers, especially their state and previous state.</li></ul><p>Of course, this depends on the issue you are trying to figure out.</p><h3 id=example-wrong-image>Example: Wrong Image<a hidden class=anchor aria-hidden=true href=#example-wrong-image>#</a></h3><p>Let&rsquo;s create a new Deployment:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl create deployment my-deployment --image<span style=color:#f92672>=</span>nginx2
</span></span></code></pre></div><p>When you execute it, you&rsquo;ll get messages like: <code>deployment.apps/my-deployment created</code>. So,
all sounds good. Let&rsquo;s check it out:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ k get deployments.apps my-deployment
</span></span><span style=display:flex><span>NAME            READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>my-deployment   0/1     <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>0</span>           85s
</span></span></code></pre></div><p>Ok, it is not been so long. Maybe it needs more time, right? Wait a bit and try again:</p><pre tabindex=0><code>❯ k get deployments.apps my-deployment
NAME            READY   UP-TO-DATE   AVAILABLE   AGE
my-deployment   0/1     1            0           2m42s
</code></pre><p>Ok, now it is time to start panicking&mldr; Just joking. In most cases, two minutes
should be enough to start a Pod unless something is wrong.</p><p>In this case, there is something wrong. Let&rsquo;s try to figure out why. First, we
can try to check deployment <code>my-deployment</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl describe deployment my-deployment
</span></span></code></pre></div><p>But all should be fine there. Let&rsquo;s check the pods:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl get pods -l app<span style=color:#f92672>=</span>my-deployment
</span></span><span style=display:flex><span>NAME                            READY   STATUS             RESTARTS   AGE
</span></span><span style=display:flex><span>my-deployment-cd98b4847-4kct6   0/1     ImagePullBackOff   <span style=color:#ae81ff>0</span>          5d16h
</span></span></code></pre></div><p>That means the image used for <code>my-deployment</code> cannot be pulled. Let&rsquo;s check
the details of the Pod:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl describe pod my-deployment-cd98b4847-4kct6
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type     Reason          Age                    From               Message
</span></span><span style=display:flex><span>  ----     ------          ----                   ----               -------
</span></span><span style=display:flex><span>  Normal   Scheduled       5d16h                  default-scheduler  Successfully assigned default/my-deployment-cd98b4847-4kct6 to lima-rancher-desktop
</span></span><span style=display:flex><span>  Normal   Pulling         5d16h <span style=color:#f92672>(</span>x4 over 5d16h<span style=color:#f92672>)</span>  kubelet            Pulling image <span style=color:#e6db74>&#34;nginx2&#34;</span>
</span></span><span style=display:flex><span>  Warning  Failed          5d16h <span style=color:#f92672>(</span>x4 over 5d16h<span style=color:#f92672>)</span>  kubelet            Failed to pull image <span style=color:#e6db74>&#34;nginx2&#34;</span>: Error response from daemon: pull access denied <span style=color:#66d9ef>for</span> nginx2, repository does not exist or may require <span style=color:#e6db74>&#39;docker login&#39;</span>: denied: requested access to the resource is denied
</span></span><span style=display:flex><span>  Warning  Failed          5d16h <span style=color:#f92672>(</span>x4 over 5d16h<span style=color:#f92672>)</span>  kubelet            Error: ErrImagePull
</span></span><span style=display:flex><span>  Warning  Failed          5d16h <span style=color:#f92672>(</span>x6 over 5d16h<span style=color:#f92672>)</span>  kubelet            Error: ImagePullBackOff
</span></span><span style=display:flex><span>  Normal   BackOff         5d16h <span style=color:#f92672>(</span>x7 over 5d16h<span style=color:#f92672>)</span>  kubelet            Back-off pulling image <span style=color:#e6db74>&#34;nginx2&#34;</span>
</span></span><span style=display:flex><span>  Warning  FailedMount     17m <span style=color:#f92672>(</span>x2 over 18m<span style=color:#f92672>)</span>      kubelet            MountVolume.SetUp failed <span style=color:#66d9ef>for</span> volume <span style=color:#e6db74>&#34;kube-api-access-kklq6&#34;</span> : object <span style=color:#e6db74>&#34;default&#34;</span>/<span style=color:#e6db74>&#34;kube-root-ca.crt&#34;</span> not registered
</span></span><span style=display:flex><span>  Normal   SandboxChanged  17m                    kubelet            Pod sandbox changed, it will be killed and re-created.
</span></span><span style=display:flex><span>  Normal   Pulling         16m <span style=color:#f92672>(</span>x4 over 17m<span style=color:#f92672>)</span>      kubelet            Pulling image <span style=color:#e6db74>&#34;nginx2&#34;</span>
</span></span><span style=display:flex><span>  Warning  Failed          15m <span style=color:#f92672>(</span>x4 over 17m<span style=color:#f92672>)</span>      kubelet            Failed to pull image <span style=color:#e6db74>&#34;nginx2&#34;</span>: Error response from daemon: pull access denied <span style=color:#66d9ef>for</span> nginx2, repository does not exist or may require <span style=color:#e6db74>&#39;docker login&#39;</span>: denied: requested access to the resource is denied
</span></span><span style=display:flex><span>  Warning  Failed          15m <span style=color:#f92672>(</span>x4 over 17m<span style=color:#f92672>)</span>      kubelet            Error: ErrImagePull
</span></span><span style=display:flex><span>  Warning  Failed          15m <span style=color:#f92672>(</span>x5 over 17m<span style=color:#f92672>)</span>      kubelet            Error: ImagePullBackOff
</span></span><span style=display:flex><span>  Normal   BackOff         2m56s <span style=color:#f92672>(</span>x57 over 17m<span style=color:#f92672>)</span>   kubelet            Back-off pulling image <span style=color:#e6db74>&#34;nginx2&#34;</span>
</span></span></code></pre></div><p>Let&rsquo;s focus just on the events. We see that the Pod fails to pull the image &ldquo;nginx2&rdquo;
because it does not exist or may require a &lsquo;docker login&rsquo;. This is indicated by
the warning messages <em>&ldquo;Failed to pull image&rdquo;</em> and <em>&ldquo;Error: ErrImagePull&rdquo;</em>. Let&rsquo;s fix it:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl set image deployment/my-deployment nginx2<span style=color:#f92672>=</span>nginx:latest
</span></span><span style=display:flex><span>deployment.apps/my-deployment image updated
</span></span></code></pre></div><p>Check again:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl get deployment my-deployment
</span></span><span style=display:flex><span>NAME             READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>my-deployment    1/1     <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>1</span>           5d16h
</span></span></code></pre></div><p>All good now.</p><h3 id=example-pod-crashing>Example: Pod crashing<a hidden class=anchor aria-hidden=true href=#example-pod-crashing>#</a></h3><p>Let&rsquo;s create a new deployment. Save below in the file and apply it:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>apps/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Deployment</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>creationTimestamp</span>: <span style=color:#66d9ef>null</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>app</span>: <span style=color:#ae81ff>stress</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>stress</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>selector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>app</span>: <span style=color:#ae81ff>stress</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>template</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>app</span>: <span style=color:#ae81ff>stress</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>image</span>: <span style=color:#ae81ff>polinux/stress</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>command</span>:
</span></span><span style=display:flex><span>          - <span style=color:#ae81ff>stress</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>args</span>: [<span style=color:#e6db74>&#34;--vm&#34;</span>, <span style=color:#e6db74>&#34;1&#34;</span>, <span style=color:#e6db74>&#34;--vm-bytes&#34;</span>, <span style=color:#e6db74>&#34;15M&#34;</span>, <span style=color:#e6db74>&#34;--vm-hang&#34;</span>, <span style=color:#e6db74>&#34;1&#34;</span>]
</span></span><span style=display:flex><span>        <span style=color:#f92672>name</span>: <span style=color:#ae81ff>stress</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>          <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>20Mi</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>10Mi</span>
</span></span></code></pre></div><p>Wait for the pods to be ready:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl get pods -w
</span></span><span style=display:flex><span>NAME                     READY   STATUS    RESTARTS      AGE
</span></span><span style=display:flex><span>stress-7d6468d54-b6mhb   1/1     Running   <span style=color:#ae81ff>1</span> <span style=color:#f92672>(</span>22h ago<span style=color:#f92672>)</span>   22h
</span></span></code></pre></div><p>Now let&rsquo;s set the memory limit to 10Mi:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl set resources deployment stress -c stress --limits<span style=color:#f92672>=</span>memory<span style=color:#f92672>=</span>10Mi
</span></span><span style=display:flex><span>deployment.apps/stress resource requirements updated
</span></span></code></pre></div><p>Check the status:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl  get pods -l app<span style=color:#f92672>=</span>stress --watch
</span></span><span style=display:flex><span>NAME                      READY   STATUS      RESTARTS      AGE
</span></span><span style=display:flex><span>stress-6c9c8f8d6b-98z7d   0/1     OOMKilled   <span style=color:#ae81ff>2</span> <span style=color:#f92672>(</span>34s ago<span style=color:#f92672>)</span>   54s
</span></span><span style=display:flex><span>stress-7d6468d54-b6mhb    1/1     Running     <span style=color:#ae81ff>1</span> <span style=color:#f92672>(</span>22h ago<span style=color:#f92672>)</span>   22h
</span></span><span style=display:flex><span>stress-6c9c8f8d6b-98z7d   0/1     CrashLoopBackOff   <span style=color:#ae81ff>2</span> <span style=color:#f92672>(</span>16s ago<span style=color:#f92672>)</span>   58s
</span></span></code></pre></div><p>As you can see, the Pod is crashing due to the memory limit being exceeded. Let&rsquo;s
describe it:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl describe pod stress-6c9c8f8d6b-98z7d
</span></span><span style=display:flex><span>Name:             stress-6c9c8f8d6b-98z7d
</span></span><span style=display:flex><span>Namespace:        default
</span></span><span style=display:flex><span>Priority:         <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>Service Account:  default
</span></span><span style=display:flex><span>Node:             lima-rancher-desktop/192.168.5.15
</span></span><span style=display:flex><span>Start Time:       Mon, <span style=color:#ae81ff>10</span> Mar <span style=color:#ae81ff>2025</span> 20:10:36 +0100
</span></span><span style=display:flex><span>Labels:           app<span style=color:#f92672>=</span>stress
</span></span><span style=display:flex><span>                  pod-template-hash<span style=color:#f92672>=</span>6c9c8f8d6b
</span></span><span style=display:flex><span>Annotations:      &lt;none&gt;
</span></span><span style=display:flex><span>Status:           Running
</span></span><span style=display:flex><span>IP:               10.42.0.107
</span></span><span style=display:flex><span>IPs:
</span></span><span style=display:flex><span>  IP:           10.42.0.107
</span></span><span style=display:flex><span>Controlled By:  ReplicaSet/stress-6c9c8f8d6b
</span></span><span style=display:flex><span>Containers:
</span></span><span style=display:flex><span>  stress:
</span></span><span style=display:flex><span>    Container ID:  docker://9b2ecba9c96c87e50229e6780c5817a26d89db095865ad2422a84e8c0a0edaa4
</span></span><span style=display:flex><span>    Image:         polinux/stress
</span></span><span style=display:flex><span>    Image ID:      docker-pullable://polinux/stress@sha256:b6144f84f9c15dac80deb48d3a646b55c7043ab1d83ea0a697c09097aaad21aa
</span></span><span style=display:flex><span>    Port:          &lt;none&gt;
</span></span><span style=display:flex><span>    Host Port:     &lt;none&gt;
</span></span><span style=display:flex><span>    Command:
</span></span><span style=display:flex><span>      stress
</span></span><span style=display:flex><span>    Args:
</span></span><span style=display:flex><span>      --vm
</span></span><span style=display:flex><span>      <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>      --vm-bytes
</span></span><span style=display:flex><span>      15M
</span></span><span style=display:flex><span>      --vm-hang
</span></span><span style=display:flex><span>      <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    State:          Waiting
</span></span><span style=display:flex><span>      Reason:       CrashLoopBackOff
</span></span><span style=display:flex><span>    Last State:     Terminated
</span></span><span style=display:flex><span>      Reason:       OOMKilled
</span></span><span style=display:flex><span>      Exit Code:    <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>      Started:      Mon, <span style=color:#ae81ff>10</span> Mar <span style=color:#ae81ff>2025</span> 20:12:54 +0100
</span></span><span style=display:flex><span>      Finished:     Mon, <span style=color:#ae81ff>10</span> Mar <span style=color:#ae81ff>2025</span> 20:12:54 +0100
</span></span><span style=display:flex><span>    Ready:          False
</span></span><span style=display:flex><span>    Restart Count:  <span style=color:#ae81ff>4</span>
</span></span><span style=display:flex><span>    Limits:
</span></span><span style=display:flex><span>      memory:  10Mi
</span></span><span style=display:flex><span>    Requests:
</span></span><span style=display:flex><span>      memory:     10Mi
</span></span><span style=display:flex><span>    Environment:  &lt;none&gt;
</span></span><span style=display:flex><span>    Mounts:
</span></span><span style=display:flex><span>      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-58ffj <span style=color:#f92672>(</span>ro<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>Conditions:
</span></span><span style=display:flex><span>  Type                        Status
</span></span><span style=display:flex><span>  PodReadyToStartContainers   True
</span></span><span style=display:flex><span>  Initialized                 True
</span></span><span style=display:flex><span>  Ready                       False
</span></span><span style=display:flex><span>  ContainersReady             False
</span></span><span style=display:flex><span>  PodScheduled                True
</span></span><span style=display:flex><span>Volumes:
</span></span><span style=display:flex><span>  kube-api-access-58ffj:
</span></span><span style=display:flex><span>    Type:                    Projected <span style=color:#f92672>(</span>a volume that contains injected data from multiple sources<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>    TokenExpirationSeconds:  <span style=color:#ae81ff>3607</span>
</span></span><span style=display:flex><span>    ConfigMapName:           kube-root-ca.crt
</span></span><span style=display:flex><span>    ConfigMapOptional:       &lt;nil&gt;
</span></span><span style=display:flex><span>    DownwardAPI:             true
</span></span><span style=display:flex><span>QoS Class:                   Burstable
</span></span><span style=display:flex><span>Node-Selectors:              &lt;none&gt;
</span></span><span style=display:flex><span>Tolerations:                 node.kubernetes.io/not-ready:NoExecute op<span style=color:#f92672>=</span>Exists <span style=color:#66d9ef>for</span> 300s
</span></span><span style=display:flex><span>                             node.kubernetes.io/unreachable:NoExecute op<span style=color:#f92672>=</span>Exists <span style=color:#66d9ef>for</span> 300s
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type     Reason     Age                  From               Message
</span></span><span style=display:flex><span>  ----     ------     ----                 ----               -------
</span></span><span style=display:flex><span>  Normal   Scheduled  2m32s                default-scheduler  Successfully assigned default/stress-6c9c8f8d6b-98z7d to lima-rancher-desktop
</span></span><span style=display:flex><span>  Normal   Pulled     2m23s                kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.201s <span style=color:#f92672>(</span>9.201s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulled     2m14s                kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.232s <span style=color:#f92672>(</span>9.232s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulled     111s                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.254s <span style=color:#f92672>(</span>9.254s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Created    74s <span style=color:#f92672>(</span>x4 over 2m23s<span style=color:#f92672>)</span>  kubelet            Created container stress
</span></span><span style=display:flex><span>  Normal   Started    74s <span style=color:#f92672>(</span>x4 over 2m23s<span style=color:#f92672>)</span>  kubelet            Started container stress
</span></span><span style=display:flex><span>  Normal   Pulled     74s                  kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.237s <span style=color:#f92672>(</span>9.237s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Warning  BackOff    37s <span style=color:#f92672>(</span>x8 over 2m13s<span style=color:#f92672>)</span>  kubelet            Back-off restarting failed container stress in pod stress-6c9c8f8d6b-98z7d_default<span style=color:#f92672>(</span>508f4d6e-5a88-4ccc-b584-a8138dfc9da9<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>  Normal   Pulling    24s <span style=color:#f92672>(</span>x5 over 2m32s<span style=color:#f92672>)</span>  kubelet            Pulling image <span style=color:#e6db74>&#34;polinux/stress&#34;</span>
</span></span></code></pre></div><p>Focus on this section:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-text data-lang=text><span style=display:flex><span>...
</span></span><span style=display:flex><span>Containers:
</span></span><span style=display:flex><span>  stress:
</span></span><span style=display:flex><span>    Container ID:  docker://9b2ecba9c96c87e50229e6780c5817a26d89db095865ad2422a84e8c0a0edaa4
</span></span><span style=display:flex><span>    Image:         polinux/stress
</span></span><span style=display:flex><span>    Image ID:      docker-pullable://polinux/stress@sha256:b6144f84f9c15dac80deb48d3a646b55c7043ab1d83ea0a697c09097aaad21aa
</span></span><span style=display:flex><span>    Port:          &lt;none&gt;
</span></span><span style=display:flex><span>    Host Port:     &lt;none&gt;
</span></span><span style=display:flex><span>    Command:
</span></span><span style=display:flex><span>      stress
</span></span><span style=display:flex><span>    Args:
</span></span><span style=display:flex><span>      --vm
</span></span><span style=display:flex><span>      1
</span></span><span style=display:flex><span>      --vm-bytes
</span></span><span style=display:flex><span>      15M
</span></span><span style=display:flex><span>      --vm-hang
</span></span><span style=display:flex><span>      1
</span></span><span style=display:flex><span>    State:          Waiting
</span></span><span style=display:flex><span>      Reason:       CrashLoopBackOff
</span></span><span style=display:flex><span>    Last State:     Terminated
</span></span><span style=display:flex><span>      Reason:       OOMKilled
</span></span><span style=display:flex><span>      Exit Code:    1
</span></span><span style=display:flex><span>      Started:      Mon, 10 Mar 2025 20:12:54 +0100
</span></span><span style=display:flex><span>      Finished:     Mon, 10 Mar 2025 20:12:54 +0100
</span></span><span style=display:flex><span>    Ready:          False
</span></span><span style=display:flex><span>    Restart Count:  4
</span></span><span style=display:flex><span>...
</span></span></code></pre></div><p>As you can see, the container is crashing due to an <em>Out Of Memory (OOM) error</em>.
This is because the container is trying to allocate more memory than is available
on the node. To fix this issue, we should increase the container&rsquo;s memory request
limit.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl set resources deployment stress -c stress --limits<span style=color:#f92672>=</span>memory<span style=color:#f92672>=</span>15Mi
</span></span><span style=display:flex><span>deployment.apps/stress resource requirements updated
</span></span></code></pre></div><p>This was intentionally set to be <em>OOMKilled</em>. But sometimes, you can have a case
when the container is restarting periodically. You notice that there are sporadical
service interruptions, but at first glance, everything is fine. Then, you should
check if the <code>Restart Count</code> is greater than 0. For this reason, check the <code>Last State</code>
section. There, you can find indications of what is going on.</p><p>In this case, I only had one container in the Pod. But sometimes, you can have a
case when multiple containers are in the Pod. In such cases, you should check the
state of all containers.</p><h3 id=missing-configuration>Missing configuration<a hidden class=anchor aria-hidden=true href=#missing-configuration>#</a></h3><p>Let&rsquo;s say you have a Deployment like this:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#f92672>apiVersion</span>: <span style=color:#ae81ff>apps/v1</span>
</span></span><span style=display:flex><span><span style=color:#f92672>kind</span>: <span style=color:#ae81ff>Deployment</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>app</span>: <span style=color:#ae81ff>stress-missing-cm</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>stress-cm</span>
</span></span><span style=display:flex><span><span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicas</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>selector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>matchLabels</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>app</span>: <span style=color:#ae81ff>stress-missing-cm</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>template</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>metadata</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>labels</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>app</span>: <span style=color:#ae81ff>stress-missing-cm</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>spec</span>:
</span></span><span style=display:flex><span>      <span style=color:#f92672>containers</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>image</span>: <span style=color:#ae81ff>polinux/stress</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>command</span>:
</span></span><span style=display:flex><span>            - <span style=color:#ae81ff>stress</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>args</span>: [<span style=color:#e6db74>&#34;--vm&#34;</span>, <span style=color:#e6db74>&#34;1&#34;</span>, <span style=color:#e6db74>&#34;--vm-bytes&#34;</span>, <span style=color:#e6db74>&#34;15M&#34;</span>, <span style=color:#e6db74>&#34;--vm-hang&#34;</span>, <span style=color:#e6db74>&#34;1&#34;</span>]
</span></span><span style=display:flex><span>          <span style=color:#f92672>name</span>: <span style=color:#ae81ff>stress</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>resources</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>limits</span>:
</span></span><span style=display:flex><span>              <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>20Mi</span>
</span></span><span style=display:flex><span>            <span style=color:#f92672>requests</span>:
</span></span><span style=display:flex><span>              <span style=color:#f92672>memory</span>: <span style=color:#ae81ff>10Mi</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>env</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>LOG_LEVEL</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>valueFrom</span>:
</span></span><span style=display:flex><span>                <span style=color:#f92672>configMapKeyRef</span>:
</span></span><span style=display:flex><span>                  <span style=color:#f92672>name</span>: <span style=color:#ae81ff>env-config</span>
</span></span><span style=display:flex><span>                  <span style=color:#f92672>key</span>: <span style=color:#ae81ff>log_level</span>
</span></span></code></pre></div><p>Save it on file <code>stress-missing-cm.yaml</code> and apply it with <code>kubectl apply -f stress-missing-cm.yaml</code>.
Wait for the pod to be created and check its status with <code>kubectl get pods -l app=stress-missing-cm -w</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl get deployments stress-cm --watch
</span></span><span style=display:flex><span>NAME        READY   UP-TO-DATE   AVAILABLE   AGE
</span></span><span style=display:flex><span>stress-cm   0/1     <span style=color:#ae81ff>1</span>            <span style=color:#ae81ff>0</span>           3m5s
</span></span></code></pre></div><p>Ok, let&rsquo;s check Pods:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl get pods -l app<span style=color:#f92672>=</span>stress-cm --watch
</span></span></code></pre></div><p>No pods? What is going on? Now, you can not use <code>kubectl describe</code> to determine what
is happening. However, you should know that K8s Deployment does not handle Pods.
It actually handles ReplicaSets, which in turn manages Pods. So, let&rsquo;s look for
the right ReplicaSets and figure out what is happening.</p><pre tabindex=0><code>❯ kubectl get replicasets
NAME                   DESIRED   CURRENT   READY   AGE
stress-5b9f9dfb49      0         0         0       23m
stress-6c9c8f8d6b      0         0         0       22h
stress-74946f474c      0         0         0       22h
stress-7d6468d54       1         1         1       22h
stress-94756c79f       0         0         0       22h
stress-94b954f85       0         0         0       22h
stress-cm-57d6cdbc9f   1         1         0       6m42s
</code></pre><p>One I&rsquo;m looking for is <code>stress-cm-57d6cdbc9f</code>. Let&rsquo;s <code>describe</code> it:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl describe replicasets stress-cm-57d6cdbc9f
</span></span><span style=display:flex><span>Name:           stress-cm-57d6cdbc9f
</span></span><span style=display:flex><span>Namespace:      default
</span></span><span style=display:flex><span>Selector:       app<span style=color:#f92672>=</span>stress-missing-cm,pod-template-hash<span style=color:#f92672>=</span>57d6cdbc9f
</span></span><span style=display:flex><span>Labels:         app<span style=color:#f92672>=</span>stress-missing-cm
</span></span><span style=display:flex><span>                pod-template-hash<span style=color:#f92672>=</span>57d6cdbc9f
</span></span><span style=display:flex><span>Annotations:    deployment.kubernetes.io/desired-replicas: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>                deployment.kubernetes.io/max-replicas: <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>                deployment.kubernetes.io/revision: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>Controlled By:  Deployment/stress-cm
</span></span><span style=display:flex><span>Replicas:       <span style=color:#ae81ff>1</span> current / <span style=color:#ae81ff>1</span> desired
</span></span><span style=display:flex><span>Pods Status:    <span style=color:#ae81ff>0</span> Running / <span style=color:#ae81ff>1</span> Waiting / <span style=color:#ae81ff>0</span> Succeeded / <span style=color:#ae81ff>0</span> Failed
</span></span><span style=display:flex><span>Pod Template:
</span></span><span style=display:flex><span>  Labels:  app<span style=color:#f92672>=</span>stress-missing-cm
</span></span><span style=display:flex><span>           pod-template-hash<span style=color:#f92672>=</span>57d6cdbc9f
</span></span><span style=display:flex><span>  Containers:
</span></span><span style=display:flex><span>   stress:
</span></span><span style=display:flex><span>    Image:      polinux/stress
</span></span><span style=display:flex><span>    Port:       &lt;none&gt;
</span></span><span style=display:flex><span>    Host Port:  &lt;none&gt;
</span></span><span style=display:flex><span>    Command:
</span></span><span style=display:flex><span>      stress
</span></span><span style=display:flex><span>    Args:
</span></span><span style=display:flex><span>      --vm
</span></span><span style=display:flex><span>      <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>      --vm-bytes
</span></span><span style=display:flex><span>      15M
</span></span><span style=display:flex><span>      --vm-hang
</span></span><span style=display:flex><span>      <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    Limits:
</span></span><span style=display:flex><span>      memory:  20Mi
</span></span><span style=display:flex><span>    Requests:
</span></span><span style=display:flex><span>      memory:  10Mi
</span></span><span style=display:flex><span>    Environment:
</span></span><span style=display:flex><span>      LOG_LEVEL:   &lt;set to the key <span style=color:#e6db74>&#39;log_level&#39;</span> of config map <span style=color:#e6db74>&#39;env-config&#39;</span>&gt;  Optional: false
</span></span><span style=display:flex><span>    Mounts:        &lt;none&gt;
</span></span><span style=display:flex><span>  Volumes:         &lt;none&gt;
</span></span><span style=display:flex><span>  Node-Selectors:  &lt;none&gt;
</span></span><span style=display:flex><span>  Tolerations:     &lt;none&gt;
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type    Reason            Age   From                   Message
</span></span><span style=display:flex><span>  ----    ------            ----  ----                   -------
</span></span><span style=display:flex><span>  Normal  SuccessfulCreate  10m   replicaset-controller  Created pod: stress-cm-57d6cdbc9f-qq4pt
</span></span></code></pre></div><p>Ok, under the Events section, the Pod was created successfully. But I can not list
this Pod with <code>kubectl get pod -l app=stress-missing-cm</code>. Let&rsquo;s try to get all Pods:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl get pods
</span></span><span style=display:flex><span>NAME                         READY   STATUS                       RESTARTS      AGE
</span></span><span style=display:flex><span>stress-7d6468d54-b6mhb       1/1     Running                      <span style=color:#ae81ff>1</span> <span style=color:#f92672>(</span>22h ago<span style=color:#f92672>)</span>   22h
</span></span><span style=display:flex><span>stress-cm-57d6cdbc9f-qq4pt   0/1     CreateContainerConfigError   <span style=color:#ae81ff>0</span>             17m
</span></span></code></pre></div><p>Oh, the pods are created, but there is a configuration error. To find out what exactly:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl describe pod stress-cm-57d6cdbc9f-qq4pt
</span></span><span style=display:flex><span>Name:             stress-cm-57d6cdbc9f-qq4pt
</span></span><span style=display:flex><span>Namespace:        default
</span></span><span style=display:flex><span>Priority:         <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>Controlled By:  ReplicaSet/stress-cm-57d6cdbc9f
</span></span><span style=display:flex><span>Containers:
</span></span><span style=display:flex><span>  stress:
</span></span><span style=display:flex><span>   ...
</span></span><span style=display:flex><span>Conditions:
</span></span><span style=display:flex><span>  Type                        Status
</span></span><span style=display:flex><span>  PodReadyToStartContainers   True
</span></span><span style=display:flex><span>  Initialized                 True
</span></span><span style=display:flex><span>  Ready                       False
</span></span><span style=display:flex><span>  ContainersReady             False
</span></span><span style=display:flex><span>  PodScheduled                True
</span></span><span style=display:flex><span>Volumes:
</span></span><span style=display:flex><span> ...
</span></span><span style=display:flex><span>Events:
</span></span><span style=display:flex><span>  Type     Reason     Age                 From               Message
</span></span><span style=display:flex><span>  ----     ------     ----                ----               -------
</span></span><span style=display:flex><span>  Normal   Scheduled  20m                 default-scheduler  Successfully assigned default/stress-cm-57d6cdbc9f-qq4pt to lima-rancher-desktop
</span></span><span style=display:flex><span>  Normal   Pulled     20m                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.179s <span style=color:#f92672>(</span>9.179s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulled     19m                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.227s <span style=color:#f92672>(</span>9.227s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulled     19m                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.21s <span style=color:#f92672>(</span>9.21s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulled     19m                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.206s <span style=color:#f92672>(</span>9.207s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulled     18m                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.247s <span style=color:#f92672>(</span>9.247s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulled     18m                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.186s <span style=color:#f92672>(</span>9.186s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulled     18m                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.205s <span style=color:#f92672>(</span>9.205s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Warning  Failed     17m <span style=color:#f92672>(</span>x8 over 20m<span style=color:#f92672>)</span>   kubelet            Error: configmap <span style=color:#e6db74>&#34;env-config&#34;</span> not found
</span></span><span style=display:flex><span>  Normal   Pulled     17m                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.342s <span style=color:#f92672>(</span>9.342s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulled     15m                 kubelet            Successfully pulled image <span style=color:#e6db74>&#34;polinux/stress&#34;</span> in 9.226s <span style=color:#f92672>(</span>9.226s including waiting<span style=color:#f92672>)</span>. Image size: <span style=color:#ae81ff>9744175</span> bytes.
</span></span><span style=display:flex><span>  Normal   Pulling    11s <span style=color:#f92672>(</span>x56 over 20m<span style=color:#f92672>)</span>  kubelet            Pulling image <span style=color:#e6db74>&#34;polinux/stress&#34;</span>
</span></span></code></pre></div><p>I can see that the image is being pulled, but the Pod can not be created because
the ConfigMap &ldquo;env-config&rdquo; is missing.</p><h3 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h3><p>As you can see from these two short examples, you can use <code>kubectl describe</code> to get
detailed information about the state of your pods and containers. This can help you
troubleshoot issues and understand what is happening with your pods. But not only
with Pods but with other resources as well.</p><h2 id=logs>Logs<a hidden class=anchor aria-hidden=true href=#logs>#</a></h2><p>You can use the <code>kubectl logs</code> command to get logs from a Pod. First, let&rsquo;s check
all pods running in the cluster:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl get -A pods
</span></span><span style=display:flex><span>NAMESPACE     NAME                                      READY   STATUS                       RESTARTS       AGE
</span></span><span style=display:flex><span>default       stress-7d6468d54-b6mhb                    1/1     Running                      <span style=color:#ae81ff>1</span> <span style=color:#f92672>(</span>23h ago<span style=color:#f92672>)</span>    23h
</span></span><span style=display:flex><span>default       stress-cm-57d6cdbc9f-qq4pt                0/1     CreateContainerConfigError   <span style=color:#ae81ff>0</span>              46m
</span></span><span style=display:flex><span>kube-system   coredns-ccb96694c-4wfcd                   1/1     Running                      <span style=color:#ae81ff>9</span> <span style=color:#f92672>(</span>23h ago<span style=color:#f92672>)</span>    37d
</span></span><span style=display:flex><span>kube-system   helm-install-traefik-crd-g5qtm            0/1     Completed                    <span style=color:#ae81ff>0</span>              37d
</span></span><span style=display:flex><span>kube-system   helm-install-traefik-njgh2                0/1     Completed                    <span style=color:#ae81ff>1</span>              37d
</span></span><span style=display:flex><span>kube-system   local-path-provisioner-5cf85fd84d-mnm84   1/1     Running                      <span style=color:#ae81ff>9</span> <span style=color:#f92672>(</span>23h ago<span style=color:#f92672>)</span>    37d
</span></span><span style=display:flex><span>kube-system   metrics-server-5985cbc9d7-96b42           1/1     Running                      <span style=color:#ae81ff>9</span> <span style=color:#f92672>(</span>23h ago<span style=color:#f92672>)</span>    37d
</span></span><span style=display:flex><span>kube-system   svclb-traefik-8ca69ac6-w26dv              2/2     Running                      <span style=color:#ae81ff>18</span> <span style=color:#f92672>(</span>23h ago<span style=color:#f92672>)</span>   37d
</span></span><span style=display:flex><span>kube-system   traefik-5d45fc8cc9-54q2b                  1/1     Running                      <span style=color:#ae81ff>9</span> <span style=color:#f92672>(</span>23h ago<span style=color:#f92672>)</span>    37d
</span></span></code></pre></div><p>I would like to see logs from the pod &ldquo;svclb-traefik-8ca69ac6-w26dv&rdquo;. This Pod has
two containers running inside it. To figure out container names, I can use the
<code>kubectl describe</code> or <code>kubectl get</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl -n kube-system describe pod svclb-traefik-8ca69ac6-w26dv
</span></span><span style=display:flex><span>...
</span></span><span style=display:flex><span>Containers:
</span></span><span style=display:flex><span>  lb-tcp-80:
</span></span><span style=display:flex><span>    Container ID:   docker://429613e67f0557c16c581c4b57fd340d8895152d9375536c115e3cfa87fff89c
</span></span><span style=display:flex><span>    Image:          rancher/klipper-lb:v0.4.9
</span></span><span style=display:flex><span>    ...
</span></span><span style=display:flex><span>  lb-tcp-443:
</span></span><span style=display:flex><span>    Container ID:   docker://7296d81188f743355d05b2538c8f88e894d17a94bb2aafa6ce3fae563cb65c8b
</span></span><span style=display:flex><span>    Image:          rancher/klipper-lb:v0.4.9
</span></span><span style=display:flex><span>    Image ID:       docker://sha256:11a5d8a9f31aad9a53ff4d20939a81ccd42fa1a47f4e52aac9ae34731d9553ee
</span></span><span style=display:flex><span>    Port:           443/TCP
</span></span><span style=display:flex><span>    Host Port:      443/TCP
</span></span><span style=display:flex><span>    State:          Running
</span></span><span style=display:flex><span>  ...
</span></span></code></pre></div><p>To see logs from the container <code>lb-tcp-80</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl -n kube-system logs svclb-traefik-8ca69ac6-w26dv lb-tcp-80
</span></span></code></pre></div><p>To see logs from the container <code>lb-tcp-443</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl -n kube-system logs svclb-traefik-8ca69ac6-w26dv lb-tcp-443
</span></span></code></pre></div><p>If you want to monitor logs, you need to add the option following <code>-f</code>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-zsh data-lang=zsh><span style=display:flex><span>❯ kubectl -n kube-system logs -f svclb-traefik-8ca69ac6-w26dv lb-tcp-80
</span></span></code></pre></div><h2 id=summary>Summary<a hidden class=anchor aria-hidden=true href=#summary>#</a></h2><p>This section covered getting logs from a Pod using the <code>kubectl logs</code> command. We
also learned how to monitor logs using the <code>-f</code> option. Finally, we saw how to get
logs from a container inside a Pod.</p><p>These two <code>kubectl</code> commands are helpful for troubleshooting and debugging issues
in Kubernetes clusters. They allow you to quickly access logs from containers running
inside Pods, which can help you identify and resolve problems more efficiently.</p><div class=subscribe><iframe src=https://rnemet.substack.com/embed width=480 height=320 style="border:1px solid #eee;background:#fff;margin:auto;display:block" frameborder=0 scrolling=no></iframe></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://rnemet.dev/tags/k8s/>K8s</a></li><li><a href=https://rnemet.dev/tags/kubernetes/>Kubernetes</a></li><li><a href=https://rnemet.dev/tags/basics/>Basics</a></li><li><a href=https://rnemet.dev/tags/kubectl/>Kubectl</a></li></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes tools: Kubectl Part 2 on x" href="https://x.com/intent/tweet/?text=Kubernetes%20tools%3a%20Kubectl%20Part%202&amp;url=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_kubectl_pt2%2f&amp;hashtags=k8s%2ckubernetes%2cbasics%2ckubectl"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes tools: Kubectl Part 2 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_kubectl_pt2%2f&amp;title=Kubernetes%20tools%3a%20Kubectl%20Part%202&amp;summary=Kubernetes%20tools%3a%20Kubectl%20Part%202&amp;source=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_kubectl_pt2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes tools: Kubectl Part 2 on reddit" href="https://reddit.com/submit?url=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_kubectl_pt2%2f&title=Kubernetes%20tools%3a%20Kubectl%20Part%202"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes tools: Kubectl Part 2 on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_kubectl_pt2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes tools: Kubectl Part 2 on whatsapp" href="https://api.whatsapp.com/send?text=Kubernetes%20tools%3a%20Kubectl%20Part%202%20-%20https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_kubectl_pt2%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes tools: Kubectl Part 2 on telegram" href="https://telegram.me/share/url?text=Kubernetes%20tools%3a%20Kubectl%20Part%202&amp;url=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_kubectl_pt2%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Kubernetes tools: Kubectl Part 2 on ycombinator" href="https://news.ycombinator.com/submitlink?t=Kubernetes%20tools%3a%20Kubectl%20Part%202&u=https%3a%2f%2frnemet.dev%2fposts%2fpractical_k8s%2fk8s_intro_kubectl_pt2%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2025 <a href=https://rnemet.dev/>DevCube</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>